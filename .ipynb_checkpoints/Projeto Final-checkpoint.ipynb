{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = './camara'\n",
    "docs = []\n",
    "files = os.listdir(PATH)\n",
    "for f in files:\n",
    "    with open(PATH + '/' + f, 'r', encoding='utf-8') as file:\n",
    "        text = ' '.join(file.read().split('-')[2:])\n",
    "        docs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './gov'\n",
    "files = os.listdir(PATH)\n",
    "for f in files:\n",
    "    with open(PATH + '/' + f, 'r', encoding='utf-8') as file:\n",
    "        docs.append(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.txt', 'w', encoding='utf-8') as f:\n",
    "    text = ''.join(docs)\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E Brasil acima de tudo e Deus acima de todos.\n",
      "36942\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "processed_docs = []\n",
    "for doc in docs:\n",
    "    sents = nltk.sent_tokenize(doc)\n",
    "    for sent in sents:\n",
    "        if sent[0] not in ['(', ')'] and 'etc' not in sent.split(' '):\n",
    "            processed_docs.append(sent)\n",
    "print(processed_docs[-2])\n",
    "print(len(processed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24766\n",
      "[' Obrigado pela oportunidade.', 'Eu estou muito feliz em retornar a esta Casa, rever velhos amigos e fazer novas amizades.(Palmas.)', 'Estamos aqui num dos centros do poder.', 'Juntos, Executivo, Legislativo e Judiciário têm um compromisso, como há pouco discursou aqui o nosso Presidente do Supremo Tribunal Federal, Ministro Toffoli.', 'A responsabilidade é de todos nós.', 'Pedimos a Deus que nos ilumine.', 'Agradeço por Ele ter salvado a minha vida há pouco tempo.', 'Quero dizer a todos: na topografia existem três nortes, o da quadrícula, o verdadeiro e o magnético, mas na democracia há só um norte: é o da nossa Constituição.(Palmas.)', 'Juntos, Presidente Toffoli, querido Rodrigo Maia e demais autoridades aqui da Mesa, vamos continuar, Presidente Temer, construindo o Brasil que o nosso povo merece.', 'Temos tudo, tudo, para sermos uma grande Nação.', 'A nossa união, que no momento estamos aqui ocupando cargos chave na República, pode, sim, mudar o destino desta grande Nação.', 'Acredito em Deus, acredito no povo brasileiro, acredito em nosso potencial.', 'Meu muito obrigado a todos.', 'Peço a Deus que nos ilumine a todos para continuarmos traçando os destinos que o nosso povo merece: a felicidade, o Brasil acima de tudo e Deus acima de todos.', 'Muito obrigado.']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "NUM_WORDS = 24766\n",
    "# NUM_WORDS = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token='<unknown>')\n",
    "tokenizer.fit_on_texts(processed_docs)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(len(tokenizer.word_index))\n",
    "print((processed_docs[0:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557204\n"
     ]
    }
   ],
   "source": [
    "max_sequence_len = 30\n",
    "\n",
    "sequences = []\n",
    "k=0\n",
    "for line in processed_docs:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "    for i in range(2, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        sequences.append(n_gram_sequence)\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=max_sequence_len+1, padding='pre')\n",
    "\n",
    "X = sequences[:, :-1]\n",
    "labels = sequences[:, -1]\n",
    "# y = to_categorical(labels, num_classes=NUM_WORDS)\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557204,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.9)\n",
    "# def shuffle(matrix, target, test_proportion):\n",
    "#     ratio = int(matrix.shape[0]/test_proportion) #should be int\n",
    "#     X_train = matrix[ratio:,:]\n",
    "#     X_test =  matrix[:ratio,:]\n",
    "#     Y_train = target[ratio:,:]\n",
    "#     Y_test =  target[:ratio,:]\n",
    "#     return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# X_train, X_test, y_train, y_test = shuffle(X, y, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9093408 mb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(sequences) / 10e6, 'mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 256)           6340096   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24766)             6364862   \n",
      "=================================================================\n",
      "Total params: 13,099,198\n",
      "Trainable params: 13,099,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NUM_WORDS, 256, input_length=max_sequence_len))\n",
    "model.add(Bidirectional(LSTM(128, dtype='float')))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(128, dtype='float'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(NUM_WORDS, activation='softmax', dtype='float'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 501483 samples, validate on 55721 samples\n",
      "Epoch 1/12\n",
      "501483/501483 [==============================] - 36s 71us/sample - loss: 6.8246 - accuracy: 0.0666 - val_loss: 6.0567 - val_accuracy: 0.1102\n",
      "Epoch 2/12\n",
      "501483/501483 [==============================] - 31s 63us/sample - loss: 5.7562 - accuracy: 0.1323 - val_loss: 5.5660 - val_accuracy: 0.1511\n",
      "Epoch 3/12\n",
      "501483/501483 [==============================] - 32s 64us/sample - loss: 5.2387 - accuracy: 0.1663 - val_loss: 5.3794 - val_accuracy: 0.1680\n",
      "Epoch 4/12\n",
      "501483/501483 [==============================] - 32s 63us/sample - loss: 4.8776 - accuracy: 0.1891 - val_loss: 5.3176 - val_accuracy: 0.1775\n",
      "Epoch 5/12\n",
      "501483/501483 [==============================] - 31s 62us/sample - loss: 4.5866 - accuracy: 0.2078 - val_loss: 5.3131 - val_accuracy: 0.1846\n",
      "Epoch 6/12\n",
      "501483/501483 [==============================] - 31s 62us/sample - loss: 4.3407 - accuracy: 0.2257 - val_loss: 5.3307 - val_accuracy: 0.1894\n",
      "Epoch 7/12\n",
      "501483/501483 [==============================] - 31s 62us/sample - loss: 4.1306 - accuracy: 0.2434 - val_loss: 5.3752 - val_accuracy: 0.1915\n",
      "Epoch 8/12\n",
      "501483/501483 [==============================] - 32s 63us/sample - loss: 3.9504 - accuracy: 0.2605 - val_loss: 5.4381 - val_accuracy: 0.1937\n",
      "Epoch 9/12\n",
      "501483/501483 [==============================] - 31s 62us/sample - loss: 3.7965 - accuracy: 0.2767 - val_loss: 5.4761 - val_accuracy: 0.1930\n",
      "Epoch 10/12\n",
      "501483/501483 [==============================] - 32s 64us/sample - loss: 3.6660 - accuracy: 0.2904 - val_loss: 5.5454 - val_accuracy: 0.1945\n",
      "Epoch 11/12\n",
      "501483/501483 [==============================] - 33s 66us/sample - loss: 3.5495 - accuracy: 0.3048 - val_loss: 5.6094 - val_accuracy: 0.1941\n",
      "Epoch 12/12\n",
      "501483/501483 [==============================] - 31s 63us/sample - loss: 3.4486 - accuracy: 0.3165 - val_loss: 5.6740 - val_accuracy: 0.1959\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=12, batch_size=4096, \n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O lula fala em uma instituição que porventura apoia a orientação de direitos humanos que seja que na coréia levando em conta as forças armadas que hoje estão lá num partido que tinha um dodói qualquer um dado é qualquer proposta de trabalho que cada vez que o congresso não progredisse apenas no brasil conseguindo um ponto de inflexão e taxou inativos hélio do supremo tribunal federal não está na questão de defesa nacional para que em audiência na reserva antes de declarar de substituir a sua igreja mas que a invalidez vai usar o réu na verdade roraima porque é o\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "seed_text = \"O lula\"\n",
    "next_words = 100\n",
    "\n",
    "index_to_word = {index: word for word, index in tokenizer.word_index.items()}\n",
    "\n",
    "T = 0.8\n",
    "\n",
    "for i in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "    probas = model.predict(token_list, verbose=0)\n",
    "    probas = np.array(probas[0][1:])\n",
    "    probas = probas ** (1.0 / T)\n",
    "    probas /= np.sum(probas)\n",
    "    predicted = np.random.choice(range(1,NUM_WORDS), p=probas)\n",
    "#     predicted = model.predict_classes(token_list, verbose=0)[0]\n",
    "    try:\n",
    "        while index_to_word[predicted] == seed_text[i-1] or index_to_word[predicted] in ['<unknown>', 'etc']:\n",
    "            predicted = np.random.choice(range(1,NUM_WORDS), p=probas)\n",
    "    except IndexError:\n",
    "        pass\n",
    "#     print(f'{list(tokenizer.word_index.keys())[1]}', probas[1]/ np.max(probas))\n",
    "    seed_text += \" \" + (index_to_word[predicted] if predicted != 0 else '')\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
