{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = './camara'\n",
    "docs = []\n",
    "files = os.listdir(PATH)\n",
    "for f in files:\n",
    "    with open(PATH + '/' + f, 'r', encoding='utf-8') as file:\n",
    "        text = ' '.join(file.read().split('-')[2:])\n",
    "        docs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './gov'\n",
    "files = os.listdir(PATH)\n",
    "for f in files:\n",
    "    with open(PATH + '/' + f, 'r', encoding='utf-8') as file:\n",
    "        docs.append(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.txt', 'w', encoding='utf-8') as f:\n",
    "    text = ''.join(docs)\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from functools import reduce\n",
    "\n",
    "# def process_doc(doc):\n",
    "#     paragraphs = doc.split('\\n      ')\n",
    "#     paragraphs[0] = ' '.join(paragraphs[0].split('\\n')[1:])\n",
    "#     paragraphs = [re.sub('\\s+', ' ', par) for par in paragraphs]\n",
    "#     paragraphs = [re.sub('^\\s+', '', par) for par in paragraphs]\n",
    "#     return paragraphs\n",
    "\n",
    "# processed_docs = reduce(lambda x, y: x + y, [process_doc(doc) for doc in docs], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E Brasil acima de tudo e Deus acima de todos.\n",
      "36942\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "processed_docs = []\n",
    "for doc in docs:\n",
    "    sents = nltk.sent_tokenize(doc)\n",
    "    for sent in sents:\n",
    "        if sent[0] not in ['(', ')'] and 'etc' not in sent.split(' '):\n",
    "            processed_docs.append(sent)\n",
    "print(processed_docs[-2])\n",
    "print(len(processed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24766\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "NUM_WORDS = 24766\n",
    "NUM_WORDS = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token='<unknown>')\n",
    "tokenizer.fit_on_texts(processed_docs)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(len(tokenizer.word_index))\n",
    "print(tokenizer.word_index['a'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = 16\n",
    "\n",
    "sequences = []\n",
    "k=0\n",
    "for line in processed_docs:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "#     if k == 5:\n",
    "#         print(token_list)\n",
    "#     k+=1\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "    sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=max_sequence_len+1, padding='pre')\n",
    "\n",
    "X = sequences[:, :-1]\n",
    "labels = sequences[:, -1]\n",
    "y = to_categorical(labels, num_classes=NUM_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.85)\n",
    "# def shuffle(matrix, target, test_proportion):\n",
    "#     ratio = int(matrix.shape[0]/test_proportion) #should be int\n",
    "#     X_train = matrix[ratio:,:]\n",
    "#     X_test =  matrix[:ratio,:]\n",
    "#     Y_train = target[ratio:,:]\n",
    "#     Y_test =  target[:ratio,:]\n",
    "#     return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# X_train, X_test, y_train, y_test = shuffle(X, y, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2512168 mb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(sequences) / 10e6, 'mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 16, 256)           2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10000)             2570000   \n",
      "=================================================================\n",
      "Total params: 5,524,240\n",
      "Trainable params: 5,524,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NUM_WORDS, 256, input_length=max_sequence_len))\n",
    "# model.add(Bidirectional(LSTM(128, dtype='float', return_sequences=True)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128, dtype='float')))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(NUM_WORDS, activation='softmax', dtype='float'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31400 samples, validate on 5542 samples\n",
      "Epoch 1/30\n",
      "31400/31400 [==============================] - 4s 136us/sample - loss: 8.1853 - accuracy: 0.0524 - val_loss: 7.4582 - val_accuracy: 0.0592\n",
      "Epoch 2/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 7.2090 - accuracy: 0.0612 - val_loss: 7.3379 - val_accuracy: 0.0592\n",
      "Epoch 3/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 6.9788 - accuracy: 0.0700 - val_loss: 7.1267 - val_accuracy: 0.0816\n",
      "Epoch 4/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 6.7247 - accuracy: 0.0922 - val_loss: 6.9113 - val_accuracy: 0.1072\n",
      "Epoch 5/30\n",
      "31400/31400 [==============================] - 1s 46us/sample - loss: 6.4034 - accuracy: 0.1208 - val_loss: 6.6466 - val_accuracy: 0.1306\n",
      "Epoch 6/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 5.9941 - accuracy: 0.1467 - val_loss: 6.3326 - val_accuracy: 0.1678\n",
      "Epoch 7/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 5.5495 - accuracy: 0.1867 - val_loss: 6.0952 - val_accuracy: 0.1931\n",
      "Epoch 8/30\n",
      "31400/31400 [==============================] - 1s 46us/sample - loss: 5.1122 - accuracy: 0.2174 - val_loss: 5.9155 - val_accuracy: 0.2156\n",
      "Epoch 9/30\n",
      "31400/31400 [==============================] - 1s 46us/sample - loss: 4.7271 - accuracy: 0.2466 - val_loss: 5.7936 - val_accuracy: 0.2348\n",
      "Epoch 10/30\n",
      "31400/31400 [==============================] - 1s 46us/sample - loss: 4.3615 - accuracy: 0.2780 - val_loss: 5.7112 - val_accuracy: 0.2485\n",
      "Epoch 11/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 4.0196 - accuracy: 0.3126 - val_loss: 5.6739 - val_accuracy: 0.2651\n",
      "Epoch 12/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 3.6975 - accuracy: 0.3446 - val_loss: 5.6677 - val_accuracy: 0.2716\n",
      "Epoch 13/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 3.3930 - accuracy: 0.3793 - val_loss: 5.6683 - val_accuracy: 0.2808\n",
      "Epoch 14/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 3.1032 - accuracy: 0.4148 - val_loss: 5.6964 - val_accuracy: 0.2846\n",
      "Epoch 15/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 2.8406 - accuracy: 0.4550 - val_loss: 5.7282 - val_accuracy: 0.2892\n",
      "Epoch 16/30\n",
      "31400/31400 [==============================] - 1s 46us/sample - loss: 2.5898 - accuracy: 0.4919 - val_loss: 5.7721 - val_accuracy: 0.2941\n",
      "Epoch 17/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 2.3662 - accuracy: 0.5336 - val_loss: 5.8388 - val_accuracy: 0.2929\n",
      "Epoch 18/30\n",
      "31400/31400 [==============================] - 1s 46us/sample - loss: 2.1601 - accuracy: 0.5664 - val_loss: 5.8883 - val_accuracy: 0.2968\n",
      "Epoch 19/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 1.9715 - accuracy: 0.6038 - val_loss: 5.9454 - val_accuracy: 0.2995\n",
      "Epoch 20/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 1.8003 - accuracy: 0.6329 - val_loss: 6.0164 - val_accuracy: 0.3028\n",
      "Epoch 21/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 1.6567 - accuracy: 0.6606 - val_loss: 6.0508 - val_accuracy: 0.3026\n",
      "Epoch 22/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 1.5202 - accuracy: 0.6889 - val_loss: 6.1264 - val_accuracy: 0.2961\n",
      "Epoch 23/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 1.3992 - accuracy: 0.7122 - val_loss: 6.1941 - val_accuracy: 0.2999\n",
      "Epoch 24/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 1.2857 - accuracy: 0.7353 - val_loss: 6.2617 - val_accuracy: 0.3019\n",
      "Epoch 25/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 1.1843 - accuracy: 0.7552 - val_loss: 6.2932 - val_accuracy: 0.3024\n",
      "Epoch 26/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 1.0930 - accuracy: 0.7763 - val_loss: 6.3846 - val_accuracy: 0.3035\n",
      "Epoch 27/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 1.0089 - accuracy: 0.7932 - val_loss: 6.4137 - val_accuracy: 0.3026\n",
      "Epoch 28/30\n",
      "31400/31400 [==============================] - 1s 46us/sample - loss: 0.9420 - accuracy: 0.8072 - val_loss: 6.4950 - val_accuracy: 0.3015\n",
      "Epoch 29/30\n",
      "31400/31400 [==============================] - 1s 47us/sample - loss: 0.8700 - accuracy: 0.8212 - val_loss: 6.5604 - val_accuracy: 0.3033\n",
      "Epoch 30/30\n",
      "31400/31400 [==============================] - 1s 45us/sample - loss: 0.8137 - accuracy: 0.8311 - val_loss: 6.6187 - val_accuracy: 0.3003\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=4096, \n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilma rousseff sras pt al documento técnico material didático política salarial estabelecido projeto aqui também mais 7 políticos cuba homossexuais também vários gay hoje também dele aqui presentes armadas lamentavelmente merece presente momento sim mesmo instrumento parado marginais gay aqui novamente exa não vale nada não nada não é ele seja fraude não tenha resposta aqui não é fácil nominal grave ali mesmo contrário queimada golpe militar outubro anos depois também melhor presos dela embora transporte depois apresentei paredão entrar capitalismo dependentes medida provisória renda 20 oficial petróleo central aqui inocentes anunciado eu qualquer crime morrendo apenas mentira tinham lá sim\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "seed_text = \"dilma\"\n",
    "next_words = 100\n",
    "\n",
    "index_to_word = {index: word for word, index in tokenizer.word_index.items()}\n",
    "\n",
    "T = 0.9\n",
    "\n",
    "for i in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "    probas = model.predict(token_list, verbose=0)\n",
    "    probas = np.array(probas[0][1:])\n",
    "    probas = probas ** (1.0 / T)\n",
    "    probas /= np.sum(probas)\n",
    "    predicted = np.random.choice(range(1,NUM_WORDS), p=probas)\n",
    "#     predicted = model.predict_classes(token_list, verbose=0)[0]\n",
    "    try:\n",
    "        while index_to_word[predicted] == seed_text[i-1] or index_to_word[predicted] in ['<unknown>', 'etc']:\n",
    "            predicted = np.random.choice(range(1,NUM_WORDS), p=probas)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    seed_text += \" \" + (index_to_word[predicted] if predicted != 0 else '')\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
